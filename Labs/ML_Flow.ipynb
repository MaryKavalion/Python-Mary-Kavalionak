{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A project involving machine learning or deep learning typically requires several steps in its workflow. In this report, we will theoretically describe these steps for a scenario using the machine learning algorithm linear regression for predicting house prices based on various features such as the number of rooms, geographic location, house size, and more.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the initial steps in a machine learning project is data collection. To predict house prices, data must be gathered, including information on the number of rooms, geographic coordinates, house size, and other relevant features. Data can be collected from various sources, such as real estate companies’ databases or government records. On this stage, identifying good data sources is important. Good data sources are ROCCC: Reliable, Original, Comprehensive, Current, Cited [1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once collected, the data needs to be stored in an appropriate format. Common formats include CSV (Comma-Separated Values), JSON (JavaScript Object Notation), AVRO (an open source project that provides data serialization and data exchange services for Apache Hadoop), Protocol Buffers from Google, Parquet and ORC (open source, column-oriented data file formats) [2]. \n",
    "\n",
    "CSV files are used widely because of their compatibility with different programs including Notepad. In Python, Pandas is used to work with CSV. They also offer more security than JSON. \n",
    "\n",
    "Unlike CSV, JSON allow to create hierarchical structure of the data.\n",
    "\n",
    "For large amount of records having a very little number of attributes a good choice is Parquet, which stores data in a columnar way. [3]\n",
    "\n",
    "It's also important to consider data privacy and security on this stage of data handling.\n",
    "For our scenario, let’s take we have an access to some large real estate company’s dataset in SQL database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning.**\n",
    "\n",
    "Data integrity is the accuracy, completeness, consistency and trustworthiness of data throughout its lifecycle. The reasons for loss of the integrity might be: data replication, data transfer and data manipulation. Other threats to data integrity are human errors, viruses, malware, hacking and system failures. Dirty data is data that is incomplete, incorrect or irrelevant to the problem we’re trying to solve, like data for house prices in Moscow, the USA, in the dataset for house prices in Moscow, Russia. Types of dirty data are: duplicate data, outdated data, incomplete data, incorrect/inaccurate data, inconsistent data. Data Cleaning may include handling missing values, removing duplicates and fixing misspellings. As our house data is stored in SQL database, we are going to clean it using SQL’s functions (e.g. UPDATE + SET, DISTINCT, WHERE + SUBSTR, TRIM (removes all blank spaces), CAST, CONCAT, COALESCE, etc. Of course, we are going to keep a Changelog – a file containing a chronologically ordered list of modifications made to the project.  [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Visualization** is another step of Data Preparation which helps to see whether there is any relevant relationship between different variables as well as show if there are any data imbalances [6] Tools like Matplotlib, Seaborn, plotnine, Plotly or Pandas in Python can be used to create visualizations like scatter plots, histograms, and heatmaps to explore relationships between features and house prices. [4] R’s ggplot2 is another powerful tool for Data Visualization. There are also tools like Tableau, which allows creating visualizations without knowing any programming languages at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our scenario, we are going to use R for data visualization. One of the most popular R packages for creating visuals is ggplot2. With its help we can create different types of plots, customize the look and feel of the plots, create high quality visuals, combine data manipulation and visualization. [7] In machine learning, we often work with high-dimensional datasets; that is, datasets consisting of many input features. However, due to the limitations of the human imagination and the written medium, conventional illustrations can only depict two (or at most three) spatial dimensions. So, we are going to use 2D scatterplots in our scenario, e.g.: house priсes (y) as a function of number of rooms (x) in plot A, house size (x) in plot B, home age (x) in plot C, etc. We are going to use smoothing as well. Smoothing enables detection of a data trend even when one can’t easily notice a trend from the plotted data points. Ggplot2’s smoothing functionality is helpful because it adds a smoothing line as another layer to a plot; the smoothing line helps the data to make sense. Also, additional parameter can be added to the plot by adding color: e.g. we can take a color scale for house prices, put geographic location to x-axis and house size on y-axis. We can also use Facet functions in R which will let us display the subsets of the data. [8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Randomization and Splitting.**\n",
    "\n",
    "Then we are going to randomize the ordering in our dataset, as we don’t want our ML model to make predictions based on the order of the information in the dataset. We will also split the data into two parts: 1 – training data (about 80% of the data) and 2 – test data to later evaluate whether the model works properly. [6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a supervised machine learning algorithm we have chosen. It attempts to explain the relationship between two variables (like house prices - y, dependent variable, and the house size – x, independent variable) using a best fitting straight line called a regression line. Linear regression has multiple possible strategies to calculate the regression line. The most popular strategy is Least Squares. It measures the vertical distance between each point and a potential regression line and adds these square distances up. The regression line will be the one where this sum is as small as possible. The regression line allows then to read the relationship and predict a target variable (the house price).[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use the training data to train the linear regression model. This includes testing and updating the values for the model's coefficients to minimize the prediction error.[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to evaluate the model's performance on the testing data that has never been used for training.[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the evaluation results, we would probably need to fine-tune the model by adjusting hyperparameters or handling outliers in the data.[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the linear regression model is trained and evaluated, it can be deployed for making predictions. Deployment can be done as a web service, or embedded within an application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Conclusion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This theoretical overview provides insight into the key steps involved in a machine learning project using linear regression to predict house prices. Each step plays a crucial role in the success of the project, from data collection to model deployment. Properly executing these steps is essential for achieving accurate predictions and valuable insights.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Google Data Analytics: Foundations: Data, Data Everywhere](https://www.coursera.org/learn/foundations-data?specialization=google-data-analytics)\n",
    "2. [Javier Ramos. Big Data File Formats Explained](https://towardsdatascience.com/big-data-file-formats-explained-dfaabe9e8b33)\n",
    "3. [Ayush Gupta. Using The Right File Format For Storing Data](https://www.analyticsvidhya.com/blog/2021/09/using-the-right-file-format-for-storing-data/)\n",
    "4. [Gilbert Tanner. Introduction to Data Visualization in Python](https://gilberttanner.com/blog/introduction-to-data-visualization-inpython/)\n",
    "5. [Google Data Analytics: Process Data from Dirty to Clean](https://www.coursera.org/learn/process-data?specialization=google-data-analytics)\n",
    "6. [Google Cloud Tech. The 7 steps of machine learning](https://www.youtube.com/watch?v=nKW8Ndu7Mjw)\n",
    "7. [Google Data Analytics: Data Analysis with R Programming](https://www.coursera.org/learn/data-analysis-r?specialization=google-data-analytics)\n",
    "8. [Sebastian Raschka. Introduction to Machine Learning and Deep Learning](https://sebastianraschka.com/blog/2020/intro-to-dl-ch01.html)\n",
    "9. [Madis Lemsalu. Simple Linear Regression for Machine Learning](https://www.youtube.com/watch?v=HoqXask9cN8)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
